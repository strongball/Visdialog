{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model.model import SentenceEncoder, SentenceDecoder, ImageEncoder, cnnTransforms, Gesd\n",
    "from dataset import VisDialDataset\n",
    "from utils.token import Lang\n",
    "\n",
    "from VQAFeature.model import VQADualModel\n",
    "from VQAFeature.utils import setDualData\n",
    "\n",
    "jsonFile = \"/home/ball/dataset/mscoco/visdialog/visdial_1.0_val.json\"\n",
    "cocoDir = \"/home/ball/dataset/mscoco/\"\n",
    "sentFeature = \"visdial_train.h5\"\n",
    "langFile = \"dataset/lang.pkl\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load lang model: dataset/lang.pkl. Word size: 43974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing image paths with image_ids: 133351it [00:00, 376983.53it/s]\n"
     ]
    }
   ],
   "source": [
    "lang = Lang.load(langFile)\n",
    "dataset = VisDialDataset(dialFile = jsonFile,\n",
    "                         cocoDir = cocoDir, \n",
    "                         sentTransform = torch.LongTensor,\n",
    "                         imgTransform = cnnTransforms,\n",
    "                         convertSentence = lang.sentenceToVector\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, \n",
    "                                     batch_size=2, \n",
    "                                     shuffle=True, \n",
    "                                     num_workers=0, \n",
    "                                     collate_fn=VisDialDataset.collate_fn)\n",
    "it = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = it.next()\n",
    "images_t, questions_t, answers_t, label_t = setDualData(data, lang, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_setting = {\n",
    "    \"output_size\": 1024,\n",
    "    \"pretrained\": False\n",
    "}\n",
    "sentence_setting = {\n",
    "    \"word_size\": len(lang),\n",
    "    \"output_size\": 512\n",
    "}\n",
    "\n",
    "model = VQADualModel(image_setting, sentence_setting).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"VQAFeature/models/dualfix/VQAmodel.2.pth\").to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gesd(torch.nn.Module):\n",
    "    def __init__(self, gamma=1, c=1, dim=1):\n",
    "        super(Gesd, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.c = c\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, f1, f2):\n",
    "        l2_norm = ((f1-f2) ** 2).sum(dim=self.dim)\n",
    "        euclidean = 1 / (1 + l2_norm)\n",
    "        sigmoid  = 1 / (1 + torch.exp(-1 * self.gamma * ((f1*f2).sum(dim=self.dim) + self.c)))\n",
    "        output = euclidean * sigmoid\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 28.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "scores = []\n",
    "for i in tqdm(range(100)):\n",
    "    data = VisDialDataset.collate_fn(dataset[i:i+1])\n",
    "    images_t, questions_t, answers_t, label_t = setDualData(data, lang, DEVICE, negsimple=0)\n",
    "    iq_outputs = model.imageQuestion(images_t, questions_t)\n",
    "    a_outputs = model.answer(answers_t)\n",
    "    scores.append(eval(iq_outputs, a_outputs))\n",
    "# torch.stack(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(0.4013), tensor(0.3724, device='cuda:0')),\n",
       " (tensor(0.4617), tensor(0.4036, device='cuda:0')),\n",
       " (tensor(0.4004), tensor(0.3810, device='cuda:0')),\n",
       " (tensor(0.6167), tensor(0.2920, device='cuda:0')),\n",
       " (tensor(0.5293), tensor(0.3317, device='cuda:0')),\n",
       " (tensor(0.4560), tensor(0.3103, device='cuda:0')),\n",
       " (tensor(0.3936), tensor(0.3613, device='cuda:0')),\n",
       " (tensor(0.5093), tensor(0.3719, device='cuda:0')),\n",
       " (tensor(0.6117), tensor(0.2983, device='cuda:0')),\n",
       " (tensor(0.3845), tensor(0.3995, device='cuda:0')),\n",
       " (tensor(0.4926), tensor(0.2993, device='cuda:0')),\n",
       " (tensor(0.5408), tensor(0.3293, device='cuda:0')),\n",
       " (tensor(0.3926), tensor(0.3467, device='cuda:0')),\n",
       " (tensor(0.5301), tensor(0.3283, device='cuda:0')),\n",
       " (tensor(0.4676), tensor(0.3884, device='cuda:0')),\n",
       " (tensor(0.5760), tensor(0.2738, device='cuda:0')),\n",
       " (tensor(0.5621), tensor(0.3154, device='cuda:0')),\n",
       " (tensor(0.7083), tensor(0.3258, device='cuda:0')),\n",
       " (tensor(0.5587), tensor(0.3359, device='cuda:0')),\n",
       " (tensor(0.5075), tensor(0.3643, device='cuda:0')),\n",
       " (tensor(0.7700), tensor(0.2844, device='cuda:0')),\n",
       " (tensor(0.7833), tensor(0.2962, device='cuda:0')),\n",
       " (tensor(0.4693), tensor(0.4481, device='cuda:0')),\n",
       " (tensor(0.5103), tensor(0.3128, device='cuda:0')),\n",
       " (tensor(0.6200), tensor(0.3406, device='cuda:0')),\n",
       " (tensor(0.4944), tensor(0.2746, device='cuda:0')),\n",
       " (tensor(0.4867), tensor(0.2749, device='cuda:0')),\n",
       " (tensor(0.5158), tensor(0.3581, device='cuda:0')),\n",
       " (tensor(0.4801), tensor(0.3498, device='cuda:0')),\n",
       " (tensor(0.3813), tensor(0.4327, device='cuda:0')),\n",
       " (tensor(0.4492), tensor(0.3268, device='cuda:0')),\n",
       " (tensor(0.5983), tensor(0.2786, device='cuda:0')),\n",
       " (tensor(0.5283), tensor(0.3335, device='cuda:0')),\n",
       " (tensor(0.4060), tensor(0.3510, device='cuda:0')),\n",
       " (tensor(0.4629), tensor(0.3345, device='cuda:0')),\n",
       " (tensor(0.4608), tensor(0.3486, device='cuda:0')),\n",
       " (tensor(0.4736), tensor(0.3083, device='cuda:0')),\n",
       " (tensor(0.3829), tensor(0.3703, device='cuda:0')),\n",
       " (tensor(0.5400), tensor(0.3289, device='cuda:0')),\n",
       " (tensor(0.4952), tensor(0.3472, device='cuda:0')),\n",
       " (tensor(0.4718), tensor(0.3807, device='cuda:0')),\n",
       " (tensor(0.4293), tensor(0.3464, device='cuda:0')),\n",
       " (tensor(0.6244), tensor(0.3198, device='cuda:0')),\n",
       " (tensor(0.6700), tensor(0.3349, device='cuda:0')),\n",
       " (tensor(0.5867), tensor(0.2953, device='cuda:0')),\n",
       " (tensor(0.4550), tensor(0.2923, device='cuda:0')),\n",
       " (tensor(0.4760), tensor(0.3744, device='cuda:0')),\n",
       " (tensor(0.3329), tensor(0.3296, device='cuda:0')),\n",
       " (tensor(0.6333), tensor(0.2838, device='cuda:0')),\n",
       " (tensor(0.3829), tensor(0.3859, device='cuda:0')),\n",
       " (tensor(0.4718), tensor(0.3664, device='cuda:0')),\n",
       " (tensor(0.6033), tensor(0.3466, device='cuda:0')),\n",
       " (tensor(0.7417), tensor(0.2983, device='cuda:0')),\n",
       " (tensor(0.6125), tensor(0.3117, device='cuda:0')),\n",
       " (tensor(0.5158), tensor(0.3411, device='cuda:0')),\n",
       " (tensor(0.5068), tensor(0.4072, device='cuda:0')),\n",
       " (tensor(0.3365), tensor(0.4355, device='cuda:0')),\n",
       " (tensor(0.5817), tensor(0.3629, device='cuda:0')),\n",
       " (tensor(0.4575), tensor(0.4370, device='cuda:0')),\n",
       " (tensor(0.3885), tensor(0.3439, device='cuda:0')),\n",
       " (tensor(0.4218), tensor(0.3348, device='cuda:0')),\n",
       " (tensor(0.5783), tensor(0.2805, device='cuda:0')),\n",
       " (tensor(0.3544), tensor(0.4350, device='cuda:0')),\n",
       " (tensor(0.5117), tensor(0.3694, device='cuda:0')),\n",
       " (tensor(0.4742), tensor(0.3535, device='cuda:0')),\n",
       " (tensor(0.5283), tensor(0.3575, device='cuda:0')),\n",
       " (tensor(0.5093), tensor(0.3463, device='cuda:0')),\n",
       " (tensor(0.6083), tensor(0.2778, device='cuda:0')),\n",
       " (tensor(0.7067), tensor(0.2817, device='cuda:0')),\n",
       " (tensor(0.3829), tensor(0.3606, device='cuda:0')),\n",
       " (tensor(0.5350), tensor(0.3012, device='cuda:0')),\n",
       " (tensor(0.4718), tensor(0.3360, device='cuda:0')),\n",
       " (tensor(0.5567), tensor(0.3078, device='cuda:0')),\n",
       " (tensor(0.4662), tensor(0.3853, device='cuda:0')),\n",
       " (tensor(0.5950), tensor(0.3244, device='cuda:0')),\n",
       " (tensor(0.3971), tensor(0.4105, device='cuda:0')),\n",
       " (tensor(0.6167), tensor(0.3156, device='cuda:0')),\n",
       " (tensor(0.4793), tensor(0.3731, device='cuda:0')),\n",
       " (tensor(0.5033), tensor(0.3159, device='cuda:0')),\n",
       " (tensor(0.4293), tensor(0.3368, device='cuda:0')),\n",
       " (tensor(0.5108), tensor(0.3620, device='cuda:0')),\n",
       " (tensor(0.5926), tensor(0.2878, device='cuda:0')),\n",
       " (tensor(0.6200), tensor(0.3093, device='cuda:0')),\n",
       " (tensor(0.4718), tensor(0.3788, device='cuda:0')),\n",
       " (tensor(0.3918), tensor(0.4147, device='cuda:0')),\n",
       " (tensor(0.7667), tensor(0.3082, device='cuda:0')),\n",
       " (tensor(0.4135), tensor(0.3494, device='cuda:0')),\n",
       " (tensor(0.5900), tensor(0.3326, device='cuda:0')),\n",
       " (tensor(0.3981), tensor(0.4046, device='cuda:0')),\n",
       " (tensor(0.7367), tensor(0.3112, device='cuda:0')),\n",
       " (tensor(0.3579), tensor(0.4346, device='cuda:0')),\n",
       " (tensor(0.5125), tensor(0.4259, device='cuda:0')),\n",
       " (tensor(0.5783), tensor(0.2937, device='cuda:0')),\n",
       " (tensor(0.4162), tensor(0.3668, device='cuda:0')),\n",
       " (tensor(0.6533), tensor(0.2852, device='cuda:0')),\n",
       " (tensor(0.6833), tensor(0.2950, device='cuda:0')),\n",
       " (tensor(0.5750), tensor(0.2834, device='cuda:0')),\n",
       " (tensor(0.3417), tensor(0.4224, device='cuda:0')),\n",
       " (tensor(0.6625), tensor(0.3249, device='cuda:0')),\n",
       " (tensor(0.5250), tensor(0.2915, device='cuda:0'))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(inputs, targets):\n",
    "    #inputs: batch * feature\n",
    "    #targets: batch * feature(each answer's feature)\n",
    "    criterion = Gesd(dim=2)\n",
    "    batch = inputs.size(0)\n",
    "    inputs = inputs.unsqueeze(1).repeat(1, batch, 1)\n",
    "    targets = targets.unsqueeze(0).repeat(batch, 1, 1)\n",
    "    \n",
    "    score = criterion(inputs, targets)\n",
    "    vals, orders = score.sort(descending=True, dim=1)\n",
    "    table = torch.arange(batch).unsqueeze(1).repeat(1, batch)\n",
    "    idx_orders = (table == orders.cpu()).nonzero()[:, 1].float()\n",
    "    mrr = (1/(idx_orders+1)).mean()\n",
    "#     mrr = idx_orders.mean()\n",
    "    return mrr.detach(), score.mean().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = eval(outputs, answers_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
